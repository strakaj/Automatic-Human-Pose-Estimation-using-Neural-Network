{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T12:54:52.762806Z",
     "iopub.status.busy": "2022-03-02T12:54:52.762269Z",
     "iopub.status.idle": "2022-03-02T12:54:53.435623Z",
     "shell.execute_reply": "2022-03-02T12:54:53.434419Z",
     "shell.execute_reply.started": "2022-03-02T12:54:52.762708Z"
    }
   },
   "outputs": [],
   "source": [
    "# paths\n",
    "!mkdir content\n",
    "weights_file = \"/kaggle/working/content/checkpoint0049.pth\"\n",
    "data_path = '/kaggle/working/content/output_data.json'\n",
    "images_path = '/kaggle/working/content/images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv5 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T12:54:53.450925Z",
     "iopub.status.busy": "2022-03-02T12:54:53.450349Z",
     "iopub.status.idle": "2022-03-02T12:55:07.282340Z",
     "shell.execute_reply": "2022-03-02T12:55:07.281504Z",
     "shell.execute_reply.started": "2022-03-02T12:54:53.450885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q gwpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T12:55:07.285841Z",
     "iopub.status.busy": "2022-03-02T12:55:07.285385Z",
     "iopub.status.idle": "2022-03-02T12:55:15.527198Z",
     "shell.execute_reply": "2022-03-02T12:55:15.526450Z",
     "shell.execute_reply.started": "2022-03-02T12:55:07.285800Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T12:55:15.528964Z",
     "iopub.status.busy": "2022-03-02T12:55:15.528706Z",
     "iopub.status.idle": "2022-03-02T12:55:15.533592Z",
     "shell.execute_reply": "2022-03-02T12:55:15.532946Z",
     "shell.execute_reply.started": "2022-03-02T12:55:15.528926Z"
    }
   },
   "outputs": [],
   "source": [
    "peson_cls = 0\n",
    "\n",
    "def to_coco_ann(coco_bb, id, score):\n",
    "    coco_ann =  {\"bbox\": coco_bb, \n",
    "               \"category_id\": 1, \n",
    "               \"image_id\": id, \n",
    "               \"score\": score}\n",
    "    return coco_ann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEPOTR Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T12:55:15.535425Z",
     "iopub.status.busy": "2022-03-02T12:55:15.534910Z",
     "iopub.status.idle": "2022-03-02T12:55:36.015042Z",
     "shell.execute_reply": "2022-03-02T12:55:36.014038Z",
     "shell.execute_reply.started": "2022-03-02T12:55:15.535384Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip uninstall gdown -y && pip install gdown\n",
    "\n",
    "import zipfile\n",
    "import sys\n",
    "import json\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T12:55:36.018249Z",
     "iopub.status.busy": "2022-03-02T12:55:36.017694Z",
     "iopub.status.idle": "2022-03-02T12:56:57.889692Z",
     "shell.execute_reply": "2022-03-02T12:56:57.888812Z",
     "shell.execute_reply.started": "2022-03-02T12:55:36.018195Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Pc26L4xKZ63KRjKRgAJb6BeqPxY90okI\n",
      "To: /kaggle/working/content/POTR2.zip\n",
      "100%|████████████████████████████████████████| 194k/194k [00:00<00:00, 85.6MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1UItWIbX5py9vGl3fL24QIjS5x_F_7MAt\n",
      "To: /kaggle/working/content/checkpoint0049.zip\n",
      "100%|█████████████████████████████████████████| 435M/435M [00:01<00:00, 256MB/s]\n",
      "/kaggle/working/content/POTR\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from -r /kaggle/working/content/POTR/requirements.txt (line 1)) (1.9.1)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from -r /kaggle/working/content/POTR/requirements.txt (line 2)) (0.10.1)\n",
      "Collecting einops\n",
      "  Downloading einops-0.4.0-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from -r /kaggle/working/content/POTR/requirements.txt (line 4)) (3.1.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from -r /kaggle/working/content/POTR/requirements.txt (line 5)) (1.20.3)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from -r /kaggle/working/content/POTR/requirements.txt (line 6)) (3.5.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from -r /kaggle/working/content/POTR/requirements.txt (line 7)) (4.62.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from -r /kaggle/working/content/POTR/requirements.txt (line 8)) (1.3.5)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.7/site-packages (from -r /kaggle/working/content/POTR/requirements.txt (line 9)) (0.11.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from -r /kaggle/working/content/POTR/requirements.txt (line 10)) (1.7.3)\n",
      "Requirement already satisfied: cython in /opt/conda/lib/python3.7/site-packages (from -r /kaggle/working/content/POTR/requirements.txt (line 11)) (0.29.27)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch->-r /kaggle/working/content/POTR/requirements.txt (line 1)) (4.0.1)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->-r /kaggle/working/content/POTR/requirements.txt (line 2)) (8.2.0)\n",
      "Requirement already satisfied: cached-property in /opt/conda/lib/python3.7/site-packages (from h5py->-r /kaggle/working/content/POTR/requirements.txt (line 4)) (1.5.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->-r /kaggle/working/content/POTR/requirements.txt (line 6)) (4.28.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->-r /kaggle/working/content/POTR/requirements.txt (line 6)) (3.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->-r /kaggle/working/content/POTR/requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->-r /kaggle/working/content/POTR/requirements.txt (line 6)) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->-r /kaggle/working/content/POTR/requirements.txt (line 6)) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->-r /kaggle/working/content/POTR/requirements.txt (line 6)) (1.3.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->-r /kaggle/working/content/POTR/requirements.txt (line 8)) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->-r /kaggle/working/content/POTR/requirements.txt (line 6)) (1.16.0)\n",
      "Installing collected packages: einops\n",
      "Successfully installed einops-0.4.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Found existing installation: matplotlib 3.5.1\n",
      "Uninstalling matplotlib-3.5.1:\n",
      "  Successfully uninstalled matplotlib-3.5.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting matplotlib==3.2.2\n",
      "  Downloading matplotlib-3.2.2-cp37-cp37m-manylinux1_x86_64.whl (12.4 MB)\n",
      "     |████████████████████████████████| 12.4 MB 4.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.2.2) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.11 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.2.2) (1.20.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.2.2) (1.3.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.2.2) (3.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.2.2) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib==3.2.2) (1.16.0)\n",
      "Installing collected packages: matplotlib\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "explainable-ai-sdk 1.3.2 requires xai-image-widget, which is not installed.\n",
      "beatrix-jupyterlab 3.1.6 requires google-cloud-bigquery-storage, which is not installed.\n",
      "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.20.3 which is incompatible.\n",
      "wfdb 3.4.1 requires matplotlib>=3.3.4, but you have matplotlib 3.2.2 which is incompatible.\n",
      "pdpbox 0.2.1 requires matplotlib==3.1.1, but you have matplotlib 3.2.2 which is incompatible.\n",
      "osmnx 1.1.1 requires matplotlib>=3.3, but you have matplotlib 3.2.2 which is incompatible.\n",
      "gwpy 2.1.3 requires matplotlib>=3.3.0, but you have matplotlib 3.2.2 which is incompatible.\n",
      "arviz 0.11.4 requires typing-extensions<4,>=3.7.4.3, but you have typing-extensions 4.0.1 which is incompatible.\u001b[0m\n",
      "Successfully installed matplotlib-3.2.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "/kaggle/working/content/POTR/deformable_potr/models/ops\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib.linux-x86_64-3.7\n",
      "creating build/lib.linux-x86_64-3.7/functions\n",
      "copying functions/ms_deform_attn_func.py -> build/lib.linux-x86_64-3.7/functions\n",
      "copying functions/__init__.py -> build/lib.linux-x86_64-3.7/functions\n",
      "creating build/lib.linux-x86_64-3.7/modules\n",
      "copying modules/__init__.py -> build/lib.linux-x86_64-3.7/modules\n",
      "copying modules/ms_deform_attn.py -> build/lib.linux-x86_64-3.7/modules\n",
      "running build_ext\n",
      "/opt/conda/lib/python3.7/site-packages/torch/utils/cpp_extension.py:370: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "  warnings.warn(msg.format('we could not find ninja.'))\n",
      "building 'MultiScaleDeformableAttention' extension\n",
      "creating build/temp.linux-x86_64-3.7\n",
      "creating build/temp.linux-x86_64-3.7/kaggle\n",
      "creating build/temp.linux-x86_64-3.7/kaggle/working\n",
      "creating build/temp.linux-x86_64-3.7/kaggle/working/content\n",
      "creating build/temp.linux-x86_64-3.7/kaggle/working/content/POTR\n",
      "creating build/temp.linux-x86_64-3.7/kaggle/working/content/POTR/deformable_potr\n",
      "creating build/temp.linux-x86_64-3.7/kaggle/working/content/POTR/deformable_potr/models\n",
      "creating build/temp.linux-x86_64-3.7/kaggle/working/content/POTR/deformable_potr/models/ops\n",
      "creating build/temp.linux-x86_64-3.7/kaggle/working/content/POTR/deformable_potr/models/ops/src\n",
      "creating build/temp.linux-x86_64-3.7/kaggle/working/content/POTR/deformable_potr/models/ops/src/cpu\n",
      "creating build/temp.linux-x86_64-3.7/kaggle/working/content/POTR/deformable_potr/models/ops/src/cuda\n",
      "gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DWITH_CUDA -I/kaggle/working/content/POTR/deformable_potr/models/ops/src -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c /kaggle/working/content/POTR/deformable_potr/models/ops/src/vision.cpp -o build/temp.linux-x86_64-3.7/kaggle/working/content/POTR/deformable_potr/models/ops/src/vision.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1013\" -DTORCH_EXTENSION_NAME=MultiScaleDeformableAttention -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++14\n",
      "\u001b[01m\u001b[Kcc1plus:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcommand line option ‘\u001b[01m\u001b[K-Wstrict-prototypes\u001b[m\u001b[K’ is valid for C/ObjC but not for C++\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Parallel.h:140\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/utils.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:13\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/kaggle/working/content/POTR/deformable_potr/models/ops/src/cpu/ms_deform_attn_cpu.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/kaggle/working/content/POTR/deformable_potr/models/ops/src/ms_deform_attn.h:13\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/kaggle/working/content/POTR/deformable_potr/models/ops/src/vision.cpp:11\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/ATen/ParallelOpenMP.h:87:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring #pragma omp parallel [\u001b[01;35m\u001b[K-Wunknown-pragmas\u001b[m\u001b[K]\n",
      "   87 | #pragma omp parallel for if ((end - begin) >= grain_size)\n",
      "      | \n",
      "In file included from \u001b[01m\u001b[K/kaggle/working/content/POTR/deformable_potr/models/ops/src/vision.cpp:11\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/kaggle/working/content/POTR/deformable_potr/models/ops/src/ms_deform_attn.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor ms_deform_attn_forward(const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, int)\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K/kaggle/working/content/POTR/deformable_potr/models/ops/src/ms_deform_attn.h:29:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "   29 |     if (value.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.is_cuda())\n",
      "      |                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/kaggle/working/content/POTR/deformable_potr/models/ops/src/cpu/ms_deform_attn_cpu.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/kaggle/working/content/POTR/deformable_potr/models/ops/src/ms_deform_attn.h:13\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/kaggle/working/content/POTR/deformable_potr/models/ops/src/vision.cpp:11\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      "  338 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
      "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/kaggle/working/content/POTR/deformable_potr/models/ops/src/vision.cpp:11\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/kaggle/working/content/POTR/deformable_potr/models/ops/src/ms_deform_attn.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kstd::vector<at::Tensor> ms_deform_attn_backward(const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, int)\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K/kaggle/working/content/POTR/deformable_potr/models/ops/src/ms_deform_attn.h:51:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "   51 |     if (value.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.is_cuda())\n",
      "      |                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/kaggle/working/content/POTR/deformable_potr/models/ops/src/cpu/ms_deform_attn_cpu.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/kaggle/working/content/POTR/deformable_potr/models/ops/src/ms_deform_attn.h:13\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/kaggle/working/content/POTR/deformable_potr/models/ops/src/vision.cpp:11\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/torch/include/ATen/core/TensorBody.h:338:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      "  338 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
      "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DWITH_CUDA -I/kaggle/working/content/POTR/deformable_potr/models/ops/src -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c /kaggle/working/content/POTR/deformable_potr/models/ops/src/cpu/ms_deform_attn_cpu.cpp -o build/temp.linux-x86_64-3.7/kaggle/working/content/POTR/deformable_potr/models/ops/src/cpu/ms_deform_attn_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1013\" -DTORCH_EXTENSION_NAME=MultiScaleDeformableAttention -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++14\n",
      "\u001b[01m\u001b[Kcc1plus:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcommand line option ‘\u001b[01m\u001b[K-Wstrict-prototypes\u001b[m\u001b[K’ is valid for C/ObjC but not for C++\n",
      "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/kaggle/working/content/POTR/deformable_potr/models/ops/src -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c /kaggle/working/content/POTR/deformable_potr/models/ops/src/cuda/ms_deform_attn_cuda.cu -o build/temp.linux-x86_64-3.7/kaggle/working/content/POTR/deformable_potr/models/ops/src/cuda/ms_deform_attn_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1013\" -DTORCH_EXTENSION_NAME=MultiScaleDeformableAttention -D_GLIBCXX_USE_CXX11_ABI=1 -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 -std=c++14\n",
      "/kaggle/working/content/POTR/deformable_potr/models/ops/src/cuda/ms_deform_im2col_cuda.cuh(261): warning: variable \"q_col\" was declared but never referenced\n",
      "          detected during instantiation of \"void ms_deformable_im2col_cuda(cudaStream_t, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *) [with scalar_t=double]\" \n",
      "/kaggle/working/content/POTR/deformable_potr/models/ops/src/cuda/ms_deform_attn_cuda.cu(64): here\n",
      "\n",
      "/kaggle/working/content/POTR/deformable_potr/models/ops/src/cuda/ms_deform_im2col_cuda.cuh(762): warning: variable \"q_col\" was declared but never referenced\n",
      "          detected during instantiation of \"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=double]\" \n",
      "/kaggle/working/content/POTR/deformable_potr/models/ops/src/cuda/ms_deform_attn_cuda.cu(134): here\n",
      "\n",
      "/kaggle/working/content/POTR/deformable_potr/models/ops/src/cuda/ms_deform_im2col_cuda.cuh(872): warning: variable \"q_col\" was declared but never referenced\n",
      "          detected during instantiation of \"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=double]\" \n",
      "/kaggle/working/content/POTR/deformable_potr/models/ops/src/cuda/ms_deform_attn_cuda.cu(134): here\n",
      "\n",
      "/kaggle/working/content/POTR/deformable_potr/models/ops/src/cuda/ms_deform_im2col_cuda.cuh(331): warning: variable \"q_col\" was declared but never referenced\n",
      "          detected during instantiation of \"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=double]\" \n",
      "/kaggle/working/content/POTR/deformable_potr/models/ops/src/cuda/ms_deform_attn_cuda.cu(134): here\n",
      "\n",
      "/kaggle/working/content/POTR/deformable_potr/models/ops/src/cuda/ms_deform_im2col_cuda.cuh(436): warning: variable \"q_col\" was declared but never referenced\n",
      "          detected during instantiation of \"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=double]\" \n",
      "/kaggle/working/content/POTR/deformable_potr/models/ops/src/cuda/ms_deform_attn_cuda.cu(134): here\n",
      "\n",
      "/kaggle/working/content/POTR/deformable_potr/models/ops/src/cuda/ms_deform_im2col_cuda.cuh(544): warning: variable \"q_col\" was declared but never referenced\n",
      "          detected during instantiation of \"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=double]\" \n",
      "/kaggle/working/content/POTR/deformable_potr/models/ops/src/cuda/ms_deform_attn_cuda.cu(134): here\n",
      "\n",
      "/kaggle/working/content/POTR/deformable_potr/models/ops/src/cuda/ms_deform_im2col_cuda.cuh(649): warning: variable \"q_col\" was declared but never referenced\n",
      "          detected during instantiation of \"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=double]\" \n",
      "/kaggle/working/content/POTR/deformable_potr/models/ops/src/cuda/ms_deform_attn_cuda.cu(134): here\n",
      "\n",
      "g++ -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.7/kaggle/working/content/POTR/deformable_potr/models/ops/src/vision.o build/temp.linux-x86_64-3.7/kaggle/working/content/POTR/deformable_potr/models/ops/src/cpu/ms_deform_attn_cpu.o build/temp.linux-x86_64-3.7/kaggle/working/content/POTR/deformable_potr/models/ops/src/cuda/ms_deform_attn_cuda.o -L/opt/conda/lib/python3.7/site-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.7/MultiScaleDeformableAttention.cpython-37m-x86_64-linux-gnu.so\n",
      "running install\n",
      "/opt/conda/lib/python3.7/site-packages/setuptools/command/install.py:37: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  setuptools.SetuptoolsDeprecationWarning,\n",
      "/opt/conda/lib/python3.7/site-packages/setuptools/command/easy_install.py:159: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
      "  EasyInstallDeprecationWarning,\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "creating MultiScaleDeformableAttention.egg-info\n",
      "writing MultiScaleDeformableAttention.egg-info/PKG-INFO\n",
      "writing dependency_links to MultiScaleDeformableAttention.egg-info/dependency_links.txt\n",
      "writing top-level names to MultiScaleDeformableAttention.egg-info/top_level.txt\n",
      "writing manifest file 'MultiScaleDeformableAttention.egg-info/SOURCES.txt'\n",
      "reading manifest file 'MultiScaleDeformableAttention.egg-info/SOURCES.txt'\n",
      "writing manifest file 'MultiScaleDeformableAttention.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "creating build/bdist.linux-x86_64\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/functions\n",
      "copying build/lib.linux-x86_64-3.7/functions/ms_deform_attn_func.py -> build/bdist.linux-x86_64/egg/functions\n",
      "copying build/lib.linux-x86_64-3.7/functions/__init__.py -> build/bdist.linux-x86_64/egg/functions\n",
      "copying build/lib.linux-x86_64-3.7/MultiScaleDeformableAttention.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/modules\n",
      "copying build/lib.linux-x86_64-3.7/modules/__init__.py -> build/bdist.linux-x86_64/egg/modules\n",
      "copying build/lib.linux-x86_64-3.7/modules/ms_deform_attn.py -> build/bdist.linux-x86_64/egg/modules\n",
      "byte-compiling build/bdist.linux-x86_64/egg/functions/ms_deform_attn_func.py to ms_deform_attn_func.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/functions/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/modules/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/modules/ms_deform_attn.py to ms_deform_attn.cpython-37.pyc\n",
      "creating stub loader for MultiScaleDeformableAttention.cpython-37m-x86_64-linux-gnu.so\n",
      "byte-compiling build/bdist.linux-x86_64/egg/MultiScaleDeformableAttention.py to MultiScaleDeformableAttention.cpython-37.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying MultiScaleDeformableAttention.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying MultiScaleDeformableAttention.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying MultiScaleDeformableAttention.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying MultiScaleDeformableAttention.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "__pycache__.MultiScaleDeformableAttention.cpython-37: module references __file__\n",
      "creating dist\n",
      "creating 'dist/MultiScaleDeformableAttention-1.0-py3.7-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing MultiScaleDeformableAttention-1.0-py3.7-linux-x86_64.egg\n",
      "creating /opt/conda/lib/python3.7/site-packages/MultiScaleDeformableAttention-1.0-py3.7-linux-x86_64.egg\n",
      "Extracting MultiScaleDeformableAttention-1.0-py3.7-linux-x86_64.egg to /opt/conda/lib/python3.7/site-packages\n",
      "Adding MultiScaleDeformableAttention 1.0 to easy-install.pth file\n",
      "\n",
      "Installed /opt/conda/lib/python3.7/site-packages/MultiScaleDeformableAttention-1.0-py3.7-linux-x86_64.egg\n",
      "Processing dependencies for MultiScaleDeformableAttention==1.0\n",
      "Finished processing dependencies for MultiScaleDeformableAttention==1.0\n"
     ]
    }
   ],
   "source": [
    "#%%capture\n",
    "#!git clone https://github.com/mhruz/POTR.git\n",
    "\n",
    "#!gdown https://drive.google.com/uc?id=1gNykuHyDgYzP56-rVRbzzAVkMGjZdONP -O /content/\n",
    "#with zipfile.ZipFile(\"/content/POTR.zip\",\"r\") as zip_ref:\n",
    "#    zip_ref.extractall(\"/content\")\n",
    "\n",
    "!gdown https://drive.google.com/uc?id=1Pc26L4xKZ63KRjKRgAJb6BeqPxY90okI -O /kaggle/working/content/\n",
    "with zipfile.ZipFile(\"/kaggle/working/content/POTR2.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"/kaggle/working/content\")\n",
    "\n",
    "#!gdown https://drive.google.com/uc?id=1s-2eP-fXU7U44RNHZ8gz5yVuKzmHaCWl -O /content/\n",
    "#with zipfile.ZipFile(\"/content/coco_dataset.zip\",\"r\") as zip_ref:\n",
    "#    zip_ref.extractall(\"/content/POTR\")\n",
    "\n",
    "    \n",
    "!gdown https://drive.google.com/uc?id=1UItWIbX5py9vGl3fL24QIjS5x_F_7MAt -O /kaggle/working/content/\n",
    "with zipfile.ZipFile(\"/kaggle/working/content/checkpoint0049.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"/kaggle/working/content\")\n",
    "\n",
    "\n",
    "%cd /kaggle/working/content/POTR\n",
    "#!pip install torch==1.5.1+cu92 torchvision==0.6.1+cu92 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "#!pip install torch==1.7.0+cu101 torchvision==0.8.0+cu101 torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "%pip install -r /kaggle/working/content/POTR/requirements.txt  \n",
    "!pip uninstall matplotlib -y\n",
    "!pip install matplotlib==3.2.2\n",
    "\n",
    "%cd /kaggle/working/content/POTR/deformable_potr/models/ops\n",
    "!sh ./make.sh\n",
    "\n",
    "sys.path.append('/kaggle/working/content/POTR/deformable_potr')\n",
    "sys.path.append('/kaggle/working/content/POTR')\n",
    "sys.path.append('/opt/conda/lib/python3.7/site-packages/MultiScaleDeformableAttention-1.0-py3.7-linux-x86_64.egg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T12:56:57.891641Z",
     "iopub.status.busy": "2022-03-02T12:56:57.891396Z",
     "iopub.status.idle": "2022-03-02T12:57:02.386253Z",
     "shell.execute_reply": "2022-03-02T12:57:02.385303Z",
     "shell.execute_reply.started": "2022-03-02T12:56:57.891604Z"
    }
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.patches import Circle\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from deformable_potr.models.deformable_potr import DeformablePOTR\n",
    "from deformable_potr.models.backbone import build_backbone\n",
    "from deformable_potr.models.deformable_transformer import build_deformable_transformer\n",
    "\n",
    "from coco_dataset.coco_dataset import COCODataset, get_final_preds\n",
    "\n",
    "device = torch.device('cuda')\n",
    "checkpoint = torch.load(weights_file, map_location=device)\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T12:57:02.388198Z",
     "iopub.status.busy": "2022-03-02T12:57:02.387951Z",
     "iopub.status.idle": "2022-03-02T12:57:16.784165Z",
     "shell.execute_reply": "2022-03-02T12:57:16.783337Z",
     "shell.execute_reply.started": "2022-03-02T12:57:02.388162Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1IgCJlPCZWu1aEIsvn1mbO1WHffpAZVkK\n",
      "To: /kaggle/working/content/images.zip\n",
      "100%|█████████████████████████████████████████| 638k/638k [00:00<00:00, 114MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1lMmo-0aDZrflJoaybQMltrtFgMl_HSEX\n",
      "To: /kaggle/working/content/v1.zip\n",
      "100%|███████████████████████████████████████| 1.97M/1.97M [00:00<00:00, 159MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1v97v9dV-ytmSPucjdtrrL1IEx4KyFUxg\n",
      "To: /kaggle/working/content/v2.zip\n",
      "100%|███████████████████████████████████████| 13.9M/13.9M [00:00<00:00, 216MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1SBTZxVX4GQqipoTJi6MaOHiYsueGzrLa\n",
      "To: /kaggle/working/content/v3.zip\n",
      "100%|███████████████████████████████████████| 3.13M/3.13M [00:00<00:00, 170MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown https://drive.google.com/uc?id=1IgCJlPCZWu1aEIsvn1mbO1WHffpAZVkK -O /kaggle/working/content/\n",
    "with zipfile.ZipFile(\"/kaggle/working/content/images.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"/kaggle/working/content\")\n",
    "\n",
    "\n",
    "\n",
    "!gdown https://drive.google.com/uc?id=1lMmo-0aDZrflJoaybQMltrtFgMl_HSEX -O /kaggle/working/content/\n",
    "with zipfile.ZipFile(\"/kaggle/working/content/v1.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"/kaggle/working/content\")\n",
    "    \n",
    "\n",
    "!gdown https://drive.google.com/uc?id=1v97v9dV-ytmSPucjdtrrL1IEx4KyFUxg -O /kaggle/working/content/\n",
    "with zipfile.ZipFile(\"/kaggle/working/content/v2.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"/kaggle/working/content\")\n",
    "    \n",
    "\n",
    "!gdown https://drive.google.com/uc?id=1SBTZxVX4GQqipoTJi6MaOHiYsueGzrLa -O /kaggle/working/content/\n",
    "with zipfile.ZipFile(\"/kaggle/working/content/v3.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"/kaggle/working/content\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T12:57:16.787762Z",
     "iopub.status.busy": "2022-03-02T12:57:16.787494Z",
     "iopub.status.idle": "2022-03-02T12:57:32.739339Z",
     "shell.execute_reply": "2022-03-02T12:57:32.738563Z",
     "shell.execute_reply.started": "2022-03-02T12:57:16.787733Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m matplotlib>=3.2.2 not found and is required by YOLOv5, attempting auto-update...\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in /opt/conda/lib/python3.7/site-packages (3.2.2)\n",
      "Requirement already satisfied: numpy>=1.11 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.2.2) (1.20.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.2.2) (1.3.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.2.2) (3.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.2.2) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.2.2) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib>=3.2.2) (1.16.0)\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m 1 package updated per /root/.cache/torch/hub/ultralytics_yolov5_master/requirements.txt\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "YOLOv5 🚀 2022-3-2 torch 1.9.1 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5s.pt to yolov5s.pt...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16b9a0b570c74a85ab408722cd539ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/14.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Summary: 213 layers, 7225885 parameters, 0 gradients, 16.5 GFLOPs\n",
      "Adding AutoShape... \n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d44cbab49a134eb7916c80790b4d375e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DeformablePOTR(\n",
       "  (transformer): DeformableTransformer(\n",
       "    (encoder): DeformableTransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): DeformableTransformerEncoderLayer(\n",
       "          (self_attn): MSDeformAttn(\n",
       "            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (attention_weights): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): DeformableTransformerEncoderLayer(\n",
       "          (self_attn): MSDeformAttn(\n",
       "            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (attention_weights): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): DeformableTransformerEncoderLayer(\n",
       "          (self_attn): MSDeformAttn(\n",
       "            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (attention_weights): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): DeformableTransformerEncoderLayer(\n",
       "          (self_attn): MSDeformAttn(\n",
       "            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (attention_weights): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): DeformableTransformerEncoderLayer(\n",
       "          (self_attn): MSDeformAttn(\n",
       "            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (attention_weights): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): DeformableTransformerEncoderLayer(\n",
       "          (self_attn): MSDeformAttn(\n",
       "            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (attention_weights): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): DeformableTransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): DeformableTransformerDecoderLayer(\n",
       "          (cross_attn): MSDeformAttn(\n",
       "            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (attention_weights): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout4): Dropout(p=0.1, inplace=False)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): DeformableTransformerDecoderLayer(\n",
       "          (cross_attn): MSDeformAttn(\n",
       "            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (attention_weights): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout4): Dropout(p=0.1, inplace=False)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): DeformableTransformerDecoderLayer(\n",
       "          (cross_attn): MSDeformAttn(\n",
       "            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (attention_weights): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout4): Dropout(p=0.1, inplace=False)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): DeformableTransformerDecoderLayer(\n",
       "          (cross_attn): MSDeformAttn(\n",
       "            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (attention_weights): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout4): Dropout(p=0.1, inplace=False)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): DeformableTransformerDecoderLayer(\n",
       "          (cross_attn): MSDeformAttn(\n",
       "            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (attention_weights): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout4): Dropout(p=0.1, inplace=False)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): DeformableTransformerDecoderLayer(\n",
       "          (cross_attn): MSDeformAttn(\n",
       "            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (attention_weights): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout4): Dropout(p=0.1, inplace=False)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (reference_points): Linear(in_features=256, out_features=2, bias=True)\n",
       "  )\n",
       "  (bbox_embed): ModuleList(\n",
       "    (0): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=256, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (1): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=256, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (2): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=256, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (3): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=256, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (4): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=256, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (5): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=256, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (query_embed): Embedding(17, 512)\n",
       "  (input_proj): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "    )\n",
       "  )\n",
       "  (backbone): Joiner(\n",
       "    (0): Backbone(\n",
       "      (body): IntermediateLayerGetter(\n",
       "        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (bn1): FrozenBatchNorm2d()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (layer1): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): FrozenBatchNorm2d()\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): FrozenBatchNorm2d()\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): FrozenBatchNorm2d()\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (4): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (5): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): FrozenBatchNorm2d()\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): PositionEmbeddingSine()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOLO Model\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_yolo = torch.hub.load('ultralytics/yolov5', 'yolov5s', device=device)  # or yolov5m, yolov5l, yolov5x, custom\n",
    "\n",
    "# DEPOTR Model\n",
    "model_depotr = DeformablePOTR(\n",
    "    build_backbone(checkpoint[\"args\"]),\n",
    "    build_deformable_transformer(checkpoint[\"args\"]),\n",
    "    num_queries=checkpoint[\"args\"].num_queries,\n",
    "    num_feature_levels=checkpoint[\"args\"].num_feature_levels\n",
    ")\n",
    "model_depotr.load_state_dict(checkpoint[\"model\"])\n",
    "model_depotr.eval()\n",
    "model_depotr.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T12:57:32.741062Z",
     "iopub.status.busy": "2022-03-02T12:57:32.740714Z",
     "iopub.status.idle": "2022-03-02T12:57:35.622754Z",
     "shell.execute_reply": "2022-03-02T12:57:35.621996Z",
     "shell.execute_reply.started": "2022-03-02T12:57:32.741023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can't receive frame (stream end?). Exiting ...\n"
     ]
    }
   ],
   "source": [
    "# Load images\n",
    "\n",
    "images = []\n",
    "#for name in os.listdir(images_path):\n",
    "#  images.append(cv2.imread(os.path.join(images_path, name))[..., ::-1])\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "cap = cv2.VideoCapture('/kaggle/working/content/v1.mp4')\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    img = frame[..., ::-1]\n",
    "    #plt.imshow(img)\n",
    "    #plt.show()\n",
    "    images.append(img)\n",
    "    name = '/kaggle/working/content/images/%012d.jpg' % i\n",
    "    cv2.imwrite(name, frame)\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T12:57:35.624862Z",
     "iopub.status.busy": "2022-03-02T12:57:35.623914Z",
     "iopub.status.idle": "2022-03-02T12:57:38.219759Z",
     "shell.execute_reply": "2022-03-02T12:57:38.218913Z",
     "shell.execute_reply.started": "2022-03-02T12:57:35.624821Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/155: 720x1280 1 person\n",
      "image 2/155: 720x1280 1 person\n",
      "image 3/155: 720x1280 1 person\n",
      "image 4/155: 720x1280 1 person\n",
      "image 5/155: 720x1280 1 person\n",
      "image 6/155: 720x1280 1 person\n",
      "image 7/155: 720x1280 1 person\n",
      "image 8/155: 720x1280 1 person\n",
      "image 9/155: 720x1280 1 person, 1 frisbee\n",
      "image 10/155: 720x1280 1 person\n",
      "image 11/155: 720x1280 1 person\n",
      "image 12/155: 720x1280 1 person\n",
      "image 13/155: 720x1280 1 person\n",
      "image 14/155: 720x1280 1 person\n",
      "image 15/155: 720x1280 1 person, 1 frisbee\n",
      "image 16/155: 720x1280 1 person\n",
      "image 17/155: 720x1280 1 person, 1 tennis racket\n",
      "image 18/155: 720x1280 1 person\n",
      "image 19/155: 720x1280 1 person\n",
      "image 20/155: 720x1280 1 person, 1 frisbee, 1 tennis racket\n",
      "image 21/155: 720x1280 1 person, 1 frisbee\n",
      "image 22/155: 720x1280 1 person\n",
      "image 23/155: 720x1280 1 person\n",
      "image 24/155: 720x1280 1 person\n",
      "image 25/155: 720x1280 1 person\n",
      "image 26/155: 720x1280 1 person\n",
      "image 27/155: 720x1280 1 person\n",
      "image 28/155: 720x1280 1 person\n",
      "image 29/155: 720x1280 1 person\n",
      "image 30/155: 720x1280 1 person\n",
      "image 31/155: 720x1280 1 person, 1 frisbee\n",
      "image 32/155: 720x1280 1 person, 1 frisbee\n",
      "image 33/155: 720x1280 1 person\n",
      "image 34/155: 720x1280 1 person, 1 frisbee\n",
      "image 35/155: 720x1280 1 person, 1 frisbee\n",
      "image 36/155: 720x1280 1 person, 1 frisbee\n",
      "image 37/155: 720x1280 1 person, 1 frisbee\n",
      "image 38/155: 720x1280 1 person, 1 frisbee\n",
      "image 39/155: 720x1280 1 person\n",
      "image 40/155: 720x1280 1 person\n",
      "image 41/155: 720x1280 1 person\n",
      "image 42/155: 720x1280 1 person, 1 frisbee\n",
      "image 43/155: 720x1280 1 person, 1 frisbee\n",
      "image 44/155: 720x1280 1 person\n",
      "image 45/155: 720x1280 1 person\n",
      "image 46/155: 720x1280 1 person\n",
      "image 47/155: 720x1280 1 person\n",
      "image 48/155: 720x1280 1 person\n",
      "image 49/155: 720x1280 1 person, 1 frisbee\n",
      "image 50/155: 720x1280 1 person, 1 frisbee\n",
      "image 51/155: 720x1280 1 person\n",
      "image 52/155: 720x1280 1 person, 1 frisbee\n",
      "image 53/155: 720x1280 1 person\n",
      "image 54/155: 720x1280 1 person\n",
      "image 55/155: 720x1280 1 person\n",
      "image 56/155: 720x1280 1 person\n",
      "image 57/155: 720x1280 1 person\n",
      "image 58/155: 720x1280 1 person\n",
      "image 59/155: 720x1280 1 person, 1 frisbee\n",
      "image 60/155: 720x1280 1 person, 1 frisbee\n",
      "image 61/155: 720x1280 1 person, 1 frisbee\n",
      "image 62/155: 720x1280 1 person, 1 frisbee\n",
      "image 63/155: 720x1280 1 person, 1 frisbee\n",
      "image 64/155: 720x1280 1 person, 1 frisbee\n",
      "image 65/155: 720x1280 1 person\n",
      "image 66/155: 720x1280 1 person\n",
      "image 67/155: 720x1280 1 person, 1 frisbee\n",
      "image 68/155: 720x1280 1 person, 1 frisbee\n",
      "image 69/155: 720x1280 1 person\n",
      "image 70/155: 720x1280 1 person\n",
      "image 71/155: 720x1280 1 person\n",
      "image 72/155: 720x1280 1 person\n",
      "image 73/155: 720x1280 1 person\n",
      "image 74/155: 720x1280 1 person\n",
      "image 75/155: 720x1280 1 person\n",
      "image 76/155: 720x1280 1 person\n",
      "image 77/155: 720x1280 1 person\n",
      "image 78/155: 720x1280 1 person\n",
      "image 79/155: 720x1280 1 person\n",
      "image 80/155: 720x1280 1 person\n",
      "image 81/155: 720x1280 1 person\n",
      "image 82/155: 720x1280 1 person\n",
      "image 83/155: 720x1280 1 person\n",
      "image 84/155: 720x1280 1 person\n",
      "image 85/155: 720x1280 1 person\n",
      "image 86/155: 720x1280 1 person\n",
      "image 87/155: 720x1280 1 person\n",
      "image 88/155: 720x1280 1 person\n",
      "image 89/155: 720x1280 1 person\n",
      "image 90/155: 720x1280 1 person, 1 frisbee\n",
      "image 91/155: 720x1280 1 person, 1 frisbee\n",
      "image 92/155: 720x1280 1 person, 1 frisbee\n",
      "image 93/155: 720x1280 1 person, 1 frisbee\n",
      "image 94/155: 720x1280 1 person, 1 frisbee\n",
      "image 95/155: 720x1280 1 person, 1 frisbee\n",
      "image 96/155: 720x1280 1 person\n",
      "image 97/155: 720x1280 1 person\n",
      "image 98/155: 720x1280 1 person\n",
      "image 99/155: 720x1280 1 person, 1 frisbee\n",
      "image 100/155: 720x1280 1 person\n",
      "image 101/155: 720x1280 1 person\n",
      "image 102/155: 720x1280 1 person\n",
      "image 103/155: 720x1280 1 person\n",
      "image 104/155: 720x1280 1 person\n",
      "image 105/155: 720x1280 1 person\n",
      "image 106/155: 720x1280 1 person\n",
      "image 107/155: 720x1280 1 person\n",
      "image 108/155: 720x1280 1 person\n",
      "image 109/155: 720x1280 1 person\n",
      "image 110/155: 720x1280 1 person\n",
      "image 111/155: 720x1280 1 person\n",
      "image 112/155: 720x1280 1 person\n",
      "image 113/155: 720x1280 1 person\n",
      "image 114/155: 720x1280 1 person\n",
      "image 115/155: 720x1280 1 person\n",
      "image 116/155: 720x1280 1 person\n",
      "image 117/155: 720x1280 1 person\n",
      "image 118/155: 720x1280 1 person\n",
      "image 119/155: 720x1280 1 person\n",
      "image 120/155: 720x1280 1 person\n",
      "image 121/155: 720x1280 1 person\n",
      "image 122/155: 720x1280 1 person\n",
      "image 123/155: 720x1280 1 person\n",
      "image 124/155: 720x1280 1 person\n",
      "image 125/155: 720x1280 1 person\n",
      "image 126/155: 720x1280 1 person\n",
      "image 127/155: 720x1280 1 person\n",
      "image 128/155: 720x1280 1 person\n",
      "image 129/155: 720x1280 1 person\n",
      "image 130/155: 720x1280 1 person\n",
      "image 131/155: 720x1280 1 person\n",
      "image 132/155: 720x1280 1 person\n",
      "image 133/155: 720x1280 1 person\n",
      "image 134/155: 720x1280 1 person\n",
      "image 135/155: 720x1280 1 person\n",
      "image 136/155: 720x1280 1 person\n",
      "image 137/155: 720x1280 1 person\n",
      "image 138/155: 720x1280 1 person\n",
      "image 139/155: 720x1280 1 person\n",
      "image 140/155: 720x1280 1 person\n",
      "image 141/155: 720x1280 1 person\n",
      "image 142/155: 720x1280 1 person\n",
      "image 143/155: 720x1280 1 person\n",
      "image 144/155: 720x1280 1 person\n",
      "image 145/155: 720x1280 1 person\n",
      "image 146/155: 720x1280 1 person\n",
      "image 147/155: 720x1280 1 person\n",
      "image 148/155: 720x1280 1 person\n",
      "image 149/155: 720x1280 1 person\n",
      "image 150/155: 720x1280 1 person\n",
      "image 151/155: 720x1280 1 person\n",
      "image 152/155: 720x1280 1 person\n",
      "image 153/155: 720x1280 1 person\n",
      "image 154/155: 720x1280 1 person\n",
      "image 155/155: 720x1280 1 person\n",
      "Speed: 6.6ms pre-process, 3.0ms inference, 1.2ms NMS per image at shape (155, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "# YOLO predict\n",
    "results = model_yolo(images, size=640)\n",
    "results.print()\n",
    "\n",
    "# sava predictions in COCO format\n",
    "results_xyxy = results.pandas().xyxy\n",
    "results_ann = []\n",
    "\n",
    "for id, img_res in enumerate(results_xyxy):\n",
    "\n",
    "    for i in range(len(img_res)):\n",
    "        row = img_res.iloc[i]\n",
    "        cls = row['class']\n",
    "        if cls == peson_cls:\n",
    "            x = row['xmin']\n",
    "            y = row['ymin']\n",
    "            w = row['xmax'] - row['xmin']\n",
    "            h = row['ymax'] - row['ymin']\n",
    "            coco_bb = [x,y,w,h]\n",
    "            conf = row['confidence']\n",
    "            results_ann.append(to_coco_ann(coco_bb, id, conf))\n",
    "\n",
    "with open(data_path, 'w') as f:\n",
    "    json.dump(results_ann, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T12:57:38.221636Z",
     "iopub.status.busy": "2022-03-02T12:57:38.221359Z",
     "iopub.status.idle": "2022-03-02T12:57:45.797593Z",
     "shell.execute_reply": "2022-03-02T12:57:45.796623Z",
     "shell.execute_reply.started": "2022-03-02T12:57:38.221596Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    }
   ],
   "source": [
    "# DEPOTR predict\n",
    "dataset_test = COCODataset(data_path, images_path, \n",
    "    transforms.Compose([transforms.ToTensor(), normalize]),\n",
    "    mode = 'test',\n",
    "    relative_positions=True)\n",
    "data_loader = DataLoader(dataset_test, batch_size=1, num_workers=0, shuffle=False)\n",
    "img_size = dataset_test.image_size\n",
    "\n",
    "\n",
    "all_preds = []\n",
    "for i, (samples, meta_data) in enumerate(data_loader):\n",
    "    \n",
    "    samples = samples.to(device, dtype=torch.float32)\n",
    "    results = model_depotr(samples).detach().cpu().numpy()\n",
    "    results = results * img_size\n",
    "\n",
    "    preds = get_final_preds(results,\n",
    "                            meta_data['center'].numpy(),\n",
    "                            meta_data['scale'].numpy(),\n",
    "                            meta_data['width'].numpy(),\n",
    "                            meta_data['height'].numpy())\n",
    "  \n",
    "    for i in range(preds.shape[0]):\n",
    "        dct = {'joints' : preds[i].tolist(), 'image_id' : int(meta_data['image_id'][i]), 'id' : int(meta_data['id'][i])} \n",
    "        all_preds.append(dct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T12:57:45.799579Z",
     "iopub.status.busy": "2022-03-02T12:57:45.799245Z",
     "iopub.status.idle": "2022-03-02T12:57:50.350036Z",
     "shell.execute_reply": "2022-03-02T12:57:50.349086Z",
     "shell.execute_reply.started": "2022-03-02T12:57:45.799535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/kaggle/working/content/images_bb': No such file or directory\n",
      "rm: cannot remove '/kaggle/working/content/images_kp': No such file or directory\n",
      "rm: cannot remove '/kaggle/working/content/images_kpl': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm -r /kaggle/working/content/images_bb\n",
    "!rm -r /kaggle/working/content/images_kp\n",
    "!rm -r /kaggle/working/content/images_kpl\n",
    "!mkdir /kaggle/working/content/images_bb\n",
    "!mkdir /kaggle/working/content/images_kp\n",
    "!mkdir /kaggle/working/content/images_kpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T12:57:50.352093Z",
     "iopub.status.busy": "2022-03-02T12:57:50.351834Z",
     "iopub.status.idle": "2022-03-02T12:58:26.937461Z",
     "shell.execute_reply": "2022-03-02T12:58:26.936712Z",
     "shell.execute_reply.started": "2022-03-02T12:57:50.352055Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, img in enumerate(images):\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(img)\n",
    "\n",
    "    for a in results_ann:\n",
    "        if i == a['image_id']:\n",
    "            ax.add_patch( Rectangle((a['bbox'][0], a['bbox'][1]),\n",
    "                          a['bbox'][2], a['bbox'][3],\n",
    "                          fc ='none', \n",
    "                          ec ='g',\n",
    "                          lw = 3) )\n",
    "    plt.savefig('/kaggle/working/content/images_bb/%012d.jpg' % i)\n",
    "    plt.close()\n",
    "  \n",
    "  #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T12:58:26.939073Z",
     "iopub.status.busy": "2022-03-02T12:58:26.938806Z",
     "iopub.status.idle": "2022-03-02T12:59:07.066952Z",
     "shell.execute_reply": "2022-03-02T12:59:07.066105Z",
     "shell.execute_reply.started": "2022-03-02T12:58:26.939037Z"
    }
   },
   "outputs": [],
   "source": [
    "colors = ['red', 'orangered', 'sienna', 'orange', 'gold', 'yellow', 'limegreen', 'green', 'turquoise', 'teal', 'steelblue', 'navy', 'slateblue','indigo', 'violet','purple','hotpink']\n",
    "\n",
    "for i, img in enumerate(images):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(img)\n",
    "    for a in all_preds:\n",
    "        if i == a['image_id']:\n",
    "            for k, j in enumerate(a['joints']):\n",
    "                ax.add_patch( Circle((j[0], j[1]), \n",
    "                                  color = colors[k],\n",
    "                                  radius = 5) )\n",
    "    plt.savefig('/kaggle/working/content/images_kp/%012d.jpg' % i)\n",
    "    plt.close()\n",
    "  #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T12:59:07.068600Z",
     "iopub.status.busy": "2022-03-02T12:59:07.068289Z",
     "iopub.status.idle": "2022-03-02T12:59:49.415834Z",
     "shell.execute_reply": "2022-03-02T12:59:49.415101Z",
     "shell.execute_reply.started": "2022-03-02T12:59:07.068543Z"
    }
   },
   "outputs": [],
   "source": [
    "keypoint_connections = [[16, 14],[14, 12],[17, 15],[15, 13],[12, 13],[6, 12],[7, 13],\n",
    "[6, 7],[6, 8],[7, 9],[8, 10],[9, 11],[2, 3],[1, 2],[1, 3],[2, 4],[3, 5],[4, 6],[5, 7]]\n",
    "\n",
    "colors = ['red', 'orangered', 'sienna', 'orange', 'gold', 'yellow', 'limegreen', 'green', 'turquoise', 'teal', 'steelblue', 'navy', 'slateblue','indigo', 'violet','purple','hotpink']\n",
    "\n",
    "for i, img in enumerate(images):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(img)\n",
    "    for a in all_preds:\n",
    "        if i == a['image_id']:\n",
    "            \n",
    "            for k, j in enumerate(a['joints']):\n",
    "                ax.add_patch( Circle((j[0], j[1]), \n",
    "                                  color = colors[k],\n",
    "                                  radius = 5) )\n",
    "            \n",
    "            kp = a['joints']\n",
    "            for idx,k in enumerate(keypoint_connections):\n",
    "                kp_id1 = k[0]-1\n",
    "                kp_id2 = k[1]-1\n",
    "                kp1_x = kp[kp_id1][0]\n",
    "                kp1_y = kp[kp_id1][1]\n",
    "                kp2_x = kp[kp_id2][0]\n",
    "                kp2_y = kp[kp_id2][1]\n",
    "                x = [kp1_x, kp2_x]\n",
    "                y = [kp1_y, kp2_y]\n",
    "                ax.add_line(Line2D(x, y, lw=2, color=colors[kp_id1], alpha=0.75))\n",
    "                    \n",
    "    plt.savefig('/kaggle/working/content/images_kpl/%012d.jpg' % i)\n",
    "    plt.close()\n",
    "    #plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T12:59:49.427183Z",
     "iopub.status.busy": "2022-03-02T12:59:49.426639Z",
     "iopub.status.idle": "2022-03-02T12:59:53.964768Z",
     "shell.execute_reply": "2022-03-02T12:59:53.963875Z",
     "shell.execute_reply.started": "2022-03-02T12:59:49.427139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/kaggle/working/content/images_kp.zip': No such file or directory\n",
      "rm: cannot remove '/kaggle/working/content/images_bb.zip': No such file or directory\n",
      "rm: cannot remove '/kaggle/working/content/images_kpl.zip': No such file or directory\n",
      "  adding: kaggle/working/content/images_kp/ (stored 0%)\n",
      "  adding: kaggle/working/content/images_kp/000000000024.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000086.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000098.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000146.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000099.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000094.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000118.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000047.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000019.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000119.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000054.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000056.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000132.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000073.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000131.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000071.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000058.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000035.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000011.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000048.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000107.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000089.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000142.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000111.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000053.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000033.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000125.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000152.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000051.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000027.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000079.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000122.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000096.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000044.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000117.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000080.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000015.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000023.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000078.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000059.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000145.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000031.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000007.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000050.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000128.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000092.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000147.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000127.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000124.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000075.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000042.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000061.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000123.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000091.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000026.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000029.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000139.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000012.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000113.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000109.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000021.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000095.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000001.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000136.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000063.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000083.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000066.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000100.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000034.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000084.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000072.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000014.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000006.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000144.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000081.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000116.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000013.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000135.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000140.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000110.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000067.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000112.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000057.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000115.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000052.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000085.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000082.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000137.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000087.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000103.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000106.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000149.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000121.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000036.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000133.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000088.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000032.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000045.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000065.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000022.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000010.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000000.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000070.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000028.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000074.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000020.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000134.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000060.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000102.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000055.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000153.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000041.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000120.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000104.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000030.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000148.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000141.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000114.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000130.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000018.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000064.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000126.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000105.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000025.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000037.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000093.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000016.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000129.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000154.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000151.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000009.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000138.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000003.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000005.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000077.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000068.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000043.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000143.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000039.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000008.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000017.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000076.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000108.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000038.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000049.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000069.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000046.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000062.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000004.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000101.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000040.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000090.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kp/000000000097.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000002.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kp/000000000150.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/ (stored 0%)\n",
      "  adding: kaggle/working/content/images_bb/000000000024.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000086.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000098.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000146.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000099.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000094.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000118.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000047.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000019.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000119.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000054.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000056.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000132.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000073.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000131.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000071.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000058.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000035.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000011.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000048.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000107.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000089.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000142.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000111.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000053.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000033.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000125.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000152.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000051.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000027.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000079.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000122.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000096.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000044.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000117.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000080.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000015.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000023.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000078.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000059.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000145.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000031.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000007.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000050.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000128.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000092.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000147.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000127.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000124.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000075.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000042.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000061.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000123.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000091.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000026.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000029.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000139.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000012.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000113.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000109.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000021.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000095.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000001.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000136.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000063.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000083.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000066.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000100.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000034.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000084.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000072.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000014.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000006.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000144.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000081.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000116.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000013.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000135.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000140.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000110.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000067.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000112.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000057.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000115.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000052.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000085.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000082.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000137.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000087.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000103.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000106.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000149.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000121.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000036.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000133.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000088.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000032.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000045.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000065.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000022.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000010.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000000.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000070.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000028.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000074.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000020.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000134.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000060.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000102.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000055.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000153.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000041.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000120.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000104.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000030.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000148.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000141.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000114.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000130.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000018.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000064.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000126.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000105.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000025.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000037.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000093.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000016.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000129.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000154.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000151.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000009.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000138.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000003.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000005.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000077.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000068.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000043.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000143.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000039.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000008.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000017.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000076.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000108.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000038.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000049.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000069.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000046.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000062.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000004.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000101.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000040.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000090.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_bb/000000000097.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000002.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_bb/000000000150.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/ (stored 0%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000024.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000086.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000098.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000146.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000099.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000094.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000118.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000047.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000019.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000119.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000054.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000056.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000132.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000073.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000131.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000071.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000058.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000035.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000011.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000048.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000107.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000089.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000142.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000111.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000053.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000033.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000125.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000152.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000051.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000027.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000079.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000122.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000096.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000044.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000117.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000080.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000015.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000023.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000078.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000059.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000145.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000031.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000007.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000050.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000128.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000092.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000147.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000127.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000124.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000075.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000042.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000061.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000123.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000091.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000026.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000029.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000139.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000012.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000113.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000109.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000021.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000095.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000001.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000136.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000063.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000083.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000066.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000100.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000034.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000084.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000072.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000014.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000006.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000144.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000081.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000116.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000013.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000135.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000140.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000110.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000067.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000112.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000057.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000115.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000052.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000085.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000082.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000137.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000087.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000103.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000106.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000149.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000121.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000036.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000133.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000088.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000032.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000045.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000065.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000022.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000010.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000000.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000070.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000028.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000074.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000020.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000134.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000060.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000102.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000055.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000153.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000041.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000120.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000104.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000030.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000148.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000141.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000114.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000130.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000018.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000064.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000126.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000105.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000025.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000037.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000093.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000016.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000129.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000154.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000151.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000009.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000138.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000003.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000005.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000077.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000068.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000043.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000143.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000039.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000008.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000017.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000076.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000108.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000038.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000049.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000069.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000046.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000062.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000004.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000101.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000040.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000090.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000097.jpg (deflated 7%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000002.jpg (deflated 8%)\n",
      "  adding: kaggle/working/content/images_kpl/000000000150.jpg (deflated 7%)\n"
     ]
    }
   ],
   "source": [
    "!rm -r /kaggle/working/content/images_kp.zip\n",
    "!rm -r /kaggle/working/content/images_bb.zip\n",
    "!rm -r /kaggle/working/content/images_kpl.zip\n",
    "\n",
    "!zip -r /kaggle/working/content/images_kp.zip /kaggle/working/content/images_kp\n",
    "!zip -r /kaggle/working/content/images_bb.zip /kaggle/working/content/images_bb\n",
    "!zip -r /kaggle/working/content/images_kpl.zip /kaggle/working/content/images_kpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
